Reservation number 430194: Reserved 16 hosts for 10800 seconds 
Run on 16 hosts for 10860 seconds from Wed Sep 26 12:33:01 2012
: node033/0 node030/0 node015/0 node017/0 node032/0 node019/0 node020/0 node021/0 node028/0 node031/0 node027/0 node041/0 node035/0 node049/0 node052/0 node054/0 
[node033:15422] mca: base: component_find: unable to open /cm/shared/apps/openmpi/intel/64/1.4.4/lib64/openmpi/mca_plm_tm: perhaps a missing symbol, or compiled for a different version of Open MPI? (ignored)
[node033:15422] mca: base: component_find: unable to open /cm/shared/apps/openmpi/intel/64/1.4.4/lib64/openmpi/mca_ras_tm: perhaps a missing symbol, or compiled for a different version of Open MPI? (ignored)
 
========================================================================
 
  I/O:
 
 io_nml namelist settings:
 
 &IO_NML
 NUM_IOTASKS     =           1,
 LREDIRECT_STDOUT        = F,
 LOG_FILENAME    = pop.out                                                                                                           
                                                                                                                                     
           ,
 LUSE_POINTER_FILES      = T,
 POINTER_FILENAME        = pointer                                                                                                   
                                                                                                                                     
                   ,
 LUSE_NF_64BIT_OFFSET    = F
 /
 
 
========================================================================
 
  Context:
 
  context_nml namelist settings:
 
 &CONTEXT_NML
 LCOUPLED        = F,
 LCCSM   = F,
 B4B_FLAG        = F
 /
 
 
========================================================================
 
 Parallel Ocean Program (POP) 
 Version 2.1alpha Jan 2005
 Modified for CCSM 
 
------------------------------------------------------------------------
 
Domain Information
 
------------------------------------------------------------------------
  Horizontal domain: nx =   3600
                     ny =   2400
  Vertical   domain: km =     42
  Number of tracers: nt =      2
  Block size:  nx_block =    229
               ny_block =    164
      max_blocks_clinic =      1
      max_blocks_tropic =      1
  Processors for baroclinic:     16
  Processors for barotropic:     16
  Distribution for baroclinic:  cartesian
  Distribution for barotropic:  cartesian
            Distribution file: unknown_di
  Number of ghost cells:  2
 
========================================================================
 
  Grid:
 
  grid_nml namelist settings:
 
 &GRID_NML
 HORIZ_GRID_OPT  = file                                                                                                              
                                                                                                                                     
           ,
 VERT_GRID_OPT   = file                                                                                                              
                                                                                                                                     
           ,
 TOPOGRAPHY_OPT  = file                                                                                                              
                                                                                                                                     
           ,
 HORIZ_GRID_FILE = /var/scratch/bwn200/pop-input/grid/grid.3600x2400.fob.da                                                          
                                                                                                                                     
           ,
 VERT_GRID_FILE  = /var/scratch/bwn200/pop-input/grid/in_depths.42.dat                                                               
                                                                                                                                     
           ,
 TOPOGRAPHY_FILE = /var/scratch/bwn200/pop-input/grid/kmt_pbc.p1_tripole.s2.0-og.20060315.no_caspian_or_black                        
                                                                                                                                     
           ,
 TOPO_SMOOTH     = F,
 FLAT_BOTTOM     = F,
 LREMOVE_POINTS  = F,
 REGION_MASK_FILE        = unknown_region_mask                                                                                       
                                                                                                                                     
                   ,
 REGION_INFO_FILE        = unknown_region_info                                                                                       
                                                                                                                                     
                   ,
 SFC_LAYER_OPT   = varthick                                                                                                          
                                                                                                                                     
           ,
 PARTIAL_BOTTOM_CELLS    = T,
 BOTTOM_CELL_FILE        = /var/scratch/bwn200/pop-input/grid/dzbc_pbc.p1_tripole.s2.0-og.20060315.no_caspian_or_black               
                                                                                                                                     
                   
 /
 Active Ocean blocks:    240
------------------------------------------------------------------------
 
POP aborting...
  clinic blocks exceed max: increase max to          15
 
------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 5 in communicator MPI_COMM_WORLD 
with errorcode 32767.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 7 with PID 5645 on
node node021 exiting without calling "finalize". This may
have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[node033:15422] 15 more processes have sent help message help-mpi-api.txt / mpi-abort
[node033:15422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
